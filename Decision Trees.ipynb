{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names = iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.write_pdf(\"iris.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  0,  0],\n",
       "       [ 0, 34,  0],\n",
       "       [ 0,  0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_train, Y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0\n",
      "Count of 0  50\n",
      "Count of 1  50\n",
      "Count of 2  50\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sepal length (cm)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-da10545ec023>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Count of 1 \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Count of 2 \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-da10545ec023>\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(df, y, unused_features)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mmax_gain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munused_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;31m# update best feature so that that particular feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# makes least number of mistakes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-da10545ec023>\u001b[0m in \u001b[0;36mgain\u001b[1;34m(df, y, s_f)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mpossible_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_f\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# total no of elements in df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sepal length (cm)'"
     ]
    }
   ],
   "source": [
    "def entropy(y):\n",
    "    # total count of elements in y\n",
    "    d=y.count()\n",
    "    #different values of y\n",
    "    vals=set(y)\n",
    "    e=0\n",
    "    for v in vals:\n",
    "        # no of elements in y with v class\n",
    "        d_o=y[y==v].count()\n",
    "        e=e-((d_o/d)*math.log(d_o/d))\n",
    "    return e\n",
    "    \n",
    "    \n",
    "def gain(df,y,s_f):\n",
    "    possible_values=set(df[s_f])\n",
    "    # total no of elements in df\n",
    "    s=y.count()\n",
    "    #entropy before split\n",
    "    entropy_s=entropy(y)\n",
    "    entropy_s_v=0\n",
    "    for val in possible_values:\n",
    "        y_o=y[df[s_f]==val]\n",
    "        #total no of elements in df with val\n",
    "        s_v=df[df[s_f]==val][s_f].count()\n",
    "        e=entropy(y_o)\n",
    "        entropy_s_v=entropy_s_v+((s_v/s)*e)\n",
    "    g=entropy_s-entropy_s_v\n",
    "    return g\n",
    "    \n",
    "    \n",
    "def build_tree(df, y, unused_features):\n",
    "    global node\n",
    "    #base case\n",
    "    # 1. unused is empty\n",
    "    if(len(unused_features)==0):\n",
    "        return\n",
    "    # 2. y contains only one distinct value\n",
    "    if(len(set(y))==1):\n",
    "        return\n",
    "    \n",
    "    best_feature = \"\"\n",
    "    max_gain=-10000\n",
    "    for f in unused_features:\n",
    "        g=gain(df,y,f)\n",
    "        # update best feature so that that particular feature\n",
    "        # makes least number of mistakes\n",
    "        if(max_gain<g):\n",
    "            max_gain=g\n",
    "            best_feature=f\n",
    "        \n",
    "    # here you should know the best feature\n",
    "    # print it out\n",
    "    print(\"Best Feature \", best_feature)\n",
    "   \n",
    "    print(\"Gain Ratio \",max_gain)\n",
    "    # remove best feature from unused features\n",
    "    unused_features.remove(best_feature)\n",
    "    # loop over possible values of best feature\n",
    "    for val in set(df[best_feature]):\n",
    "        df_r=df[df[f]==val]\n",
    "        y_r=y[df[f]==val]\n",
    "        print(\"Node\",node)\n",
    "        print(\"Count of 0 \",y_r[y_r==0].count())\n",
    "        print(\"Count of 1 \",y_r[y_r==1].count())\n",
    "        print(\"Count of 2 \",y_r[y_r==2].count())\n",
    "        print(\"Current Entropy \",entropy(y_r))\n",
    "        if(entropy(y_r)==0):\n",
    "            print(\"Reached leaf\")\n",
    "        else:\n",
    "            print(\"Gain Ratio \",max_gain)\n",
    "        # call build tree recursively\n",
    "        node+=1\n",
    "        build_tree(df_r,y_r,unused_features)\n",
    "    \n",
    "      \n",
    "y = pd.DataFrame(iris.target)\n",
    "y=y[0]\n",
    "node=1\n",
    "unused_features = set(iris.feature_names)\n",
    "print(\"Node 0\")\n",
    "print(\"Count of 0 \",y[y==0].count())\n",
    "print(\"Count of 1 \",y[y==1].count())\n",
    "print(\"Count of 2 \",y[y==2].count())\n",
    "build_tree(df, y, unused_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
