{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters=3)\n",
    "k_means.fit(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0,\n",
       "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.85      , 3.07368421, 5.74210526, 2.07105263],\n",
       "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.333333333333334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for i in range(len(iris.target)):\n",
    "    if iris.target[i] == k_means.labels_[i]:\n",
    "        score += 1\n",
    "accuracy = score / 150\n",
    "accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters=2)\n",
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.33333333, 9.        ],\n",
       "       [1.16666667, 1.46666667]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c = k_means.labels_)\n",
    "plt.scatter(k_means.cluster_centers_[0, 0], k_means.cluster_centers_[0, 1], c = 'r')\n",
    "plt.scatter(k_means.cluster_centers_[1, 0], k_means.cluster_centers_[1, 1], c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code implementation for K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data, k = 2, max_iter = 100):\n",
    "    means = []\n",
    "    # randomly initialize the mean values\n",
    "    # we take top k values as mean values initially\n",
    "    for i in range(k):\n",
    "        means.append(data[i])\n",
    "    \n",
    "    # loop for max_iter\n",
    "    for j in range(max_iter):\n",
    "        # assign data points to the clusters they belong to\n",
    "        clusters = []\n",
    "        # create empty clusters\n",
    "        for j in range(k):\n",
    "            clusters.append([])\n",
    "        for point in data:\n",
    "            # find distance to all mean values\n",
    "            distances = [((point - m)**2).sum() for m in means]\n",
    "            # find min distance\n",
    "            minDistance = min(distances)\n",
    "            # find mean for which we get min distance\n",
    "            l = distances.index(minDistance)\n",
    "            # add this point to the cluster\n",
    "            clusters[l].append(point)\n",
    "        # calculate new mean values\n",
    "        change = False\n",
    "        for j in range(k):\n",
    "            new_mean = np.average(clusters[j], axis = 0)\n",
    "            # if the mean changes, ie, it is not equal to old mean, change = True\n",
    "            if not np.array_equal(means[j], new_mean):\n",
    "                change = True\n",
    "            means[j] = new_mean\n",
    "        if not change:\n",
    "            break\n",
    "        return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, means):\n",
    "    predictions = []\n",
    "    for point in test_data:\n",
    "        distances = [((point - m) ** 2).sum() for m in means]\n",
    "        minDistance = min(distances)\n",
    "        l = distances.index(minDistance)\n",
    "        predictions.append(l)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 2.]), array([4.9 , 5.88])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = fit(X)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, k = 10, max_iter = 100):\n",
    "        print(\"constructor\")\n",
    "        self.k = k\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def fit(self, data):\n",
    "        self.means = []\n",
    "        # randomly initialize the mean values\n",
    "        # we take top k values as mean values initially\n",
    "        for i in range(self.k):\n",
    "            self.means.append(data[i])\n",
    "\n",
    "        # loop for max_iter\n",
    "        for j in range(self.max_iter):\n",
    "            # assign data points to the clusters they belong to\n",
    "            clusters = []\n",
    "            # create empty clusters\n",
    "            for j in range(self.k):\n",
    "                clusters.append([])\n",
    "            for point in data:\n",
    "                # find distance to all mean values\n",
    "                distances = [((point - m)**2).sum() for m in self.means]\n",
    "                # find min distance\n",
    "                minDistance = min(distances)\n",
    "                # find mean for which we get min distance\n",
    "                l = distances.index(minDistance)\n",
    "                # add this point to the cluster\n",
    "                clusters[l].append(point)\n",
    "            # calculate new mean values\n",
    "            change = False\n",
    "            for j in range(self.k):\n",
    "                new_mean = np.average(clusters[j], axis = 0)\n",
    "                # if the mean changes, ie, it is not equal to old mean, change = True\n",
    "                if not np.array_equal(self.means[j], new_mean):\n",
    "                    change = True\n",
    "                self.means[j] = new_mean\n",
    "            if not change:\n",
    "                break\n",
    "    def predict(self, test_data):\n",
    "        predictions = []\n",
    "        for point in test_data:\n",
    "            distances = [((point - m) ** 2).sum() for m in self.means]\n",
    "            minDistance = min(distances)\n",
    "            l = distances.index(minDistance)\n",
    "            predictions.append(l)\n",
    "        return predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor\n"
     ]
    }
   ],
   "source": [
    "k_means = K_Means(k = 2, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
