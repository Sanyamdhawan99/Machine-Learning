{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for and function\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1,1]])\n",
    "y = np.array([[0, 0, 0, 1]]).T\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sig(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of sigmoid function\n",
    "def derivativeSig(z):\n",
    "    return sig(z) * (1 - sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.08503303],\n",
       "        [-0.37916862]]), array([0.93018352]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for no hidden layer\n",
    "weights = 2 * np.random.random((2, 1)) - 1\n",
    "bias = 2 * np.random.random(1) - 1\n",
    "lr = 0.1\n",
    "num_of_iterations = 10000\n",
    "weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29509114],\n",
       "       [0.14313875],\n",
       "       [0.23847872],\n",
       "       [0.11108407]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward propagation whith no hidden layer\n",
    "output0 = x\n",
    "output = sig(np.dot(output0, weights) + bias)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.49024288e-04],\n",
       "       [5.58441501e-02],\n",
       "       [5.58441504e-02],\n",
       "       [9.33532218e-01]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for itr in range(num_of_iterations):\n",
    "    output0 = x\n",
    "    output = sig(np.dot(output0, weights) + bias)\n",
    "    first_term = output - y\n",
    "    input_for_last_layer = np.dot(output0, weights) + bias\n",
    "    second_term = derivativeSig(input_for_last_layer)\n",
    "    first_two = first_term * second_term\n",
    "    changes = np.array([[0.0], [0.0]]) # same dimension as weights\n",
    "    for i in range(2): # for weights\n",
    "        for j in range(4): # for features\n",
    "            changes[i][0] += first_two[j][0] * output0[j][i]\n",
    "    weights = weights - lr * changes\n",
    "    bias_change = 0.0\n",
    "    for j in range(4):\n",
    "        bias_change += first_two[j][0] * 1 # bias initial value is always 1\n",
    "    bias = bias - lr * bias_change\n",
    "output = sig(np.dot(output0, weights) + bias)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.49068349e-04],\n",
       "       [5.58472418e-02],\n",
       "       [5.58472420e-02],\n",
       "       [9.33528514e-01]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing for loops using vector operation\n",
    "for itr in range(num_of_iterations):\n",
    "    output0 = x\n",
    "    output = sig(np.dot(output0, weights) + bias)\n",
    "    first_term = output - y\n",
    "    input_for_last_layer = np.dot(output0, weights) + bias\n",
    "    second_term = derivativeSig(input_for_last_layer)\n",
    "    first_two = first_term * second_term\n",
    "    changes = np.dot(output0.T, first_two)\n",
    "    weights = weights - lr * changes\n",
    "    bias_change = np.sum(first_two)\n",
    "    bias = bias - lr * bias_change\n",
    "output = sig(np.dot(output0, weights) + bias)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.66696827, -0.98905007],\n",
       "        [ 0.76453844,  0.88171894]]),\n",
       " array([[ 0.43901882, -0.43775203]]),\n",
       " array([[-0.35015857],\n",
       "        [ 0.04761434]]),\n",
       " array([[-0.95496953]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 1 hidden layer\n",
    "wh = 2 * np.random.random((2, 2)) - 1\n",
    "bh = 2 * np.random.random((1, 2)) - 1\n",
    "wo = 2 * np.random.random((2, 1)) - 1\n",
    "bo = 2 * np.random.random((1, 1)) - 1\n",
    "wh, bh, wo, bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24063583],\n",
       "       [0.23231423],\n",
       "       [0.22990393],\n",
       "       [0.22427695]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0 = x\n",
    "output_hidden = sig(np.dot(output0, wh) + bh)\n",
    "output = sig(np.dot(output_hidden, wo) + bo)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR using neural network with hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for XOR\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivativeSig(z):\n",
    "    return sig(z) * (1 - sig(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hidden layer weights\n",
    "wh = 2 * np.random.random((2, 2)) - 1\n",
    "bh = 2 * np.random.random((1, 2)) - 1\n",
    "wo = 2 * np.random.random((2, 1)) - 1\n",
    "bo = 2 * np.random.random((1, 1)) - 1\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.07878795],\n",
       "        [0.92803473],\n",
       "        [0.92816798],\n",
       "        [0.08731997]]), array([[-4.15336117,  6.29965218],\n",
       "        [-4.14718326,  6.26320585]]), array([[ 6.19610113, -2.70339745]]), array([[6.53414426],\n",
       "        [6.32000242]]), array([[-9.37651577]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward propagation with one hidden layer\n",
    "for itr in range(10000):\n",
    "    output0 = x\n",
    "    inputHidden = np.dot(output0, wh) + bh\n",
    "    outputHidden = sig(inputHidden)\n",
    "    input_for_output_layer = np.dot(outputHidden, wo) + bo\n",
    "    output = sig(input_for_output_layer)\n",
    "\n",
    "    first_term_output_layer = output - y\n",
    "    second_term_output_layer = derivativeSig(input_for_output_layer)\n",
    "    first_two_output_layer = first_term_output_layer * second_term_output_layer\n",
    "\n",
    "    first_term_hidden_layer = np.dot(first_two_output_layer, wo.T)\n",
    "    second_term_hidden_layer = derivativeSig(inputHidden)\n",
    "    first_two_hidden_layer = first_term_hidden_layer * second_term_hidden_layer\n",
    "\n",
    "    # for finding changes, we use output of previous layer and multiply it with first_two of present layer\n",
    "    changes_output = np.dot(outputHidden.T, first_two_output_layer)\n",
    "    changes_output_bias = np.sum(first_two_output_layer, axis=0, keepdims=True)\n",
    "\n",
    "    changes_hidden = np.dot(output0.T, first_two_hidden_layer)\n",
    "    changes_hidden_bias = np.sum(first_two_hidden_layer, axis=0, keepdims=True)\n",
    "\n",
    "    wo = wo - lr * changes_output\n",
    "    bo = bo - lr * changes_output_bias\n",
    "    \n",
    "    wh = wh - lr * changes_hidden\n",
    "    bh = bh - lr * changes_hidden_bias\n",
    "\n",
    "output0 = x\n",
    "inputHidden = np.dot(output0, wh) + bh\n",
    "outputHidden = sig(inputHidden)\n",
    "input_for_output_layer = np.dot(outputHidden, wo) + bo\n",
    "output = sig(input_for_output_layer)\n",
    "output, wh, bh, wo, bo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
